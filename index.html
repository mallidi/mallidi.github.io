<html><head><title>Harish Mallidi</title></head><body bgcolor="#ffffff">

<table WIDTH="100%" border="0">
<tbody>
 <tr valign="top">
  <td rowspan="2" align="left"><img src="images/Harish.jpg" border="0" style="width:128px;height:128px;">
  </td> 
  <td align="right" width="500">
  <img src="images/clsp.gif" alt="CLSP">
  </td>
 </tr>

 <tr valign="bottom">
  <td align="right">
   <table>
    <tbody>
    <tr align="right"><td><strong><font size="+2">Harish Mallidi</font></strong></td></tr>
    <tr align="right"><td>Ph.D Student</td></tr>
    <tr align="right"><td><a href="http://www.clsp.jhu.edu">The Center for Language and Speech Processing (CLSP)</a></td></tr>
    <tr align="right"><td><a href="http://www.ece-jhu.org/">Department of Electrical and Computer Engineering</a></td></tr>
    <tr align="right"><td><a href="http://www.jhu.edu">Johns Hopkins University</a></td></tr>
    <tr align="right">
    <td>email: last_name@jhu.edu</a></td>
    </tr>
    <tr align="right">
    <td>www: <a href="http://mallidi.github.io">http://mallidi.github.io</a></td></tr>
   </tbody>
   </table>
  </td>
 </tr>
</tbody>
</table>
<HR>

<H2>Interests</H2>
<UL><LI>
Automatic speech recognition, Speech signal processing, Language identification, Speaker recognition, Machine learning.
</LI></UL>

<H2>Education</H2>
<UL><LI>
June 2004 - August 2010, Bachelor of Technology + Master of Science (Electronics and Communication Engineering), <a href="https://www.iiit.ac.in/">https://www.iiit.ac.in/</a>, India
</LI></UL>

<UL><LI>
September 2011 - , Doctor of Philosophy, <a href="http://www.clsp.jhu.edu">The Center for Language and Speech Processing (CLSP)</a>, <a href="http://www.ece-jhu.org">Johns Hopkins University (JHU)</a>, USA, supervised by <a href="http://www.clsp.jhu.edu/~hynek/">Prof. Hynek Hermansky</a>
<br>
<br>
<UL><LI>Thesis Proposal - <em><a href="pdfs/HarishThesisProposal.pdf">Performance Monitor Techniques for Noise Robust Speech Recognition</a></em>, December 2014.
</LI></UL>
<!-- <UL><LI>Thesis - <em><a href="pdfs/phd-thesis.pdf">Data-driven Neural Network Based Feature Front-ends for Automatic Speech Recognition</a></em>, December 2012. -->
<!-- </LI></UL> -->
</LI></UL>

<H2>Experience</H2>

<b>NIST Language Recognition Evaluation 2015</b>, Nov 2015 
<UL><LI>
Participated as part of Brno University of Technology team in NIST LRE15 evals.
</UL></LI>
<UL><LI>
Application of DNNs to classify languages directly, instead of conventional usage as bottleneck feature extractor.
</UL></LI>

<b>IARPA ASpIRE Challenge 2015</b>, Feb`15 
<UL><LI>
Participated as part of BBN team.
</UL></LI>
<UL><LI>
Noise robust ASR based on FDLP based modulation features.
</UL></LI>

<b>Fred Jelinek Memorial Workshop</b>, Prague, July`14 - Aug.`14
<UL><LI>
Part of the team focusing on Unsupervised Confidence Estimation of Neural Networks 
</UL></LI>

<UL><LI>
Application: Noise Robust Speech Recognition
</UL></LI>

<b>Contribution to KALDI speech recognition toolkit</b>, Dec.`13 - present 
<UL><LI>
Involved in implementation of 2D Convolutional Neural Networks (CNNs) in KALDI.
</UL></LI>

<b>Research Intern at BBN Technologies</b> May `13 - Aug.`13 
<UL><LI>
Involved in the implementation of Neural Network based features in BBNâ€™s Byblos speech recognition toolkit.
</UL></LI>

<UL><LI>
The features have been successfully used in 2014 DARPA RATS and IARPA BABEL evaluations.
</UL></LI>

<H2>Publications</H2>

<b>In Journals</b>

<UL><LI>
S. Ganapathy, <b>Sri Harish Mallidi</b>, and H. Hermansky, ``<em>Robust Feature Extraction Using Modula- tion Filtering of Autoregressive Models</em>'', IEEE Transactions on Audio, Speech and Language Proc. June 2014 (<a href="pdfs/2DAR_ModFilt.pdf">pdf</a>)
</UL></LI>

<UL><LI>
S. Garimella, <b>Sri Harish Mallidi</b>, and H. Hermansky, ``<em>Regularized Auto-Associative Neural Net- works for Speaker Verification</em>'', IEEE Signal Processing Letters. Dec. 2012 (<a href="pdfs/GarimellaLetters2012.pdf">pdf</a>)
</UL></LI>

<b>In Conferences</b>
<UL><LI>
<b>Sri Harish Mallidi</b>, H Hermansky ``<em>Novel Neural Network Based Fusion for Multistream ASR</em>'', Accepted in ICASSP 2016, Shanghai, Mar., 2016. 
</UL></LI>

<UL><LI>
<b>Sri Harish Mallidi</b>, T Ogawa, H Hermansky ``<em>Uncertainty Estimation of DNN classifiers</em>'', IEEE ASRU 2015, Scottsdale, Dec., 2015. (<a href="pdfs/Harish_asru15.pdf">pdf</a>) 
</UL></LI>

<UL><LI>
<b>Sri Harish Mallidi</b>, T Ogawa, K Vesely, P S Nidadavolu, H Hermansky ``<em>Autoencoder based multi-stream combination for noise robust speech recognition</em>'', Interspeech, Dresden, Sept., 2015. (<a href="pdfs/mallidi_interspeech2015_IS150897.pdf">pdf</a>)
</UL></LI>

<UL><LI>
Hynek Hermansky, et. al. ``<em>Towards machines that know when they do not know: Summary of work done at 2014 Frederick Jelinek Memorial Workshop</em>'', ICASSP 2015 (<a href="pdfs/PragueWSPaper.pdf">pdf</a>)
</UL></LI>


<UL><LI>
Tim Ng, et. al, ``<em>Progress in the BBN Keyword Search System for the DARPA RATS Program</em>'', Interspeech, Singapore, Sept., 2014. (<a href="pdfs/ng_interspeech2014_IS141010.pdf">pdf</a>)
</UL></LI>

<UL><LI>
P Matejka, L Zhang, T Ng, <b>Sri Harish Mallidi</b>, et. al. ``<em>Neural Network Bottleneck Features for Language Identification</em>'', ISCA Speaker Odyssey, Joensuu, June, 2014.  (<a href="pdfs/matejka_odyssey2014_299-304-35.pdf">pdf</a>) 
</UL></LI>

<UL><LI>
<b>Sri Harish Mallidi</b>, Sriram Ganapathy and Hynek Hermansky, ``<em>Robust Speaker Recognition Using Spectro-Temporal Autoregressive Models</em>'', Interspeech, Lyon, Aug. 2013. (<a href="pdfs/plp2_spkr.pdf">pdf</a>)
</UL></LI>

<UL><LI>
Jeff Ma, Bing Zhang, Spyros Matsoukas, <b>Sri Harish Mallidi</b>, Feipeng Li, Hynek Hermansky,``<em>Improvements in Language Identification on the RATS Noisy Speech Corpus</em>'', Interspeech, Lyon, Aug. 2013.
</UL></LI>

<UL><LI>
Pascal Clark, <b>Sri Harish Mallidi</b>, Aren Jansen, and Hynek Hermansky, ``<em>Frequency Offset Correction in Speech without Detecting Pitch</em>'', ICASSP, Vancouver, 2013. (<a href="pdfs/ICASSP2013c.pdf">pdf</a>)
</UL></LI>

<UL><LI>
Oldrich Plchot, et.al, ``<em>Developing a Speaker Identification System for the DARPA RATS Project</em>'', ICASSP, Vancouver, Canada, May 2013 (<a href="pdfs/sid_rats.pdf">pdf</a>)
</LI></UL>

<UL><LI>
Samuel Thomas, <b>Sri Harish Mallidi</b>, Thomas Janu, Hynek Hermansky, Nima Mesgarani, Xinhui Zhou, Shihab Shamma, Tim Ng, Bing Zhang, Long Nguyen and Spyros Matsoukas, ``<em>Acoustic and Data-driven Features for Robust Speech Activity Detection</em>'', Interspeech, 2012 (<a href="pdfs/sad.pdf">pdf</a>)
</LI></UL>

<UL><LI>
Feipeng Li, <b>Sri Harish Mallidi</b> and H. Hermansky, ``<em>Phone recognition in critical bands using sub-band temporal modulations TODO: Change PDF</em>'', Interspeech, 2012. (<a href="pdfs/sad.pdf">pdf</a>)
</LI></UL>

<UL><LI>
Samuel Thomas, <b>Sri Harish Mallidi</b>, Sriram Ganapathy and Hynek Hermansky, ``<em>Adaptation Transforms of Auto-Associative Neural Networks as Features for Speaker Verification</em>'', Odyssey Speaker and Language Recognition Workshop, Singapore, June 2012 (<a href="pdfs/aann.pdf">pdf</a>)
</LI></UL>

<UL><LI>
Daniel Garcia-Romero, Xinhui Zhou et al. <em>The UMD-JHU 2011 Speaker Recognition System</em>, ICASSP, Kyoto, Japan, March 2012 (<a href="pdfs/umd_jhu_spk.pdf">pdf</a>) 
</LI></UL>

<UL><LI>
<b>Sri Harish Mallidi</b>, Sriram Ganapathy and Hynek Hermansky, ``<em>Modulation spectrum analysis for recognition of reverberant speech</em>'', Interspeech, 2011. (<a href="pdfs/analysis_ams_robustness.pdf">pdf</a>)
</LI></UL>

<UL><LI>
<b>Sri Harish Mallidi</b>, Kishore S. Prahallad, Suryakanth V Gangashetty and B. Yegnanarayana, ``<em>Significance of Pitch Synchronous Analysis for Speaker Recognition using AANN Models</em>'', Interspeech, 2010. (<a href="pdfs/Harish-IS2010.pdf">pdf</a>)
</LI></UL>

<UL><LI>
Anand Joseph M., <b>Sri Harish Mallidi</b> and B. Yegnanarayana, ``<em>Speaker Dependent Mapping of Source and System features for Enhancement of Throat Microphone Speech</em>'', Interspeech, 2010. (<a href="pdfs/Anand-IS2010.pdf">pdf</a>)
</LI></UL>


<UL><LI>
Sudheer Kovela, <b>Sri Harish Mallidi</b>, Sri Rama Murty K and B. Yegnanarayana, ``<em>Analysis of laugh signals for detecting in continuous speech</em>'', Interspeech, 2009. (<a href="pdfs/SudhHariMurtyYegnaIS2009.pdf">pdf</a>)
</LI></UL>




<H2>Teaching</H2>
<UL><LI>Teaching Assistant for <em>Processing of Audio and Visual Signals</em></a>, Fall-2012, 2013, Spring-2016</LI></UL>

<UL><LI>Teaching Assistant for <em>Speech and Auditory Processing by Humans and Machines</em></a>, Spring-2013, 2013 </LI></UL>

<!-- <H2>Contact Information</H2>
The Center for Language and Speech Processing,
<br>Computational Science and Engineering Building,
<br>Room 323,
<br>3400 North Charles Street,
<br>Baltimore, MD 21218. -->

<small> <b>Copyright Notice</b> - This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder. </small>

<!-- Start of StatCounter Code -->
<script type="text/javascript">
var sc_project=6448115; 
var sc_invisible=1; 
var sc_security="a65516f7"; 
</script>

<script type="text/javascript"
src="http://www.statcounter.com/counter/counter.js"></script><noscript><div
class="statcounter"><a title="website statistics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="http://c.statcounter.com/6448115/0/a65516f7/1/"
alt="website statistics" ></a></div></noscript>
<!-- End of StatCounter Code -->
</body>
</html>
